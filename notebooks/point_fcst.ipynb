{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Change native directory to root\n",
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evgenygenov/miniforge3/envs/conformal/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/Users/evgenygenov/miniforge3/envs/conformal/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/Users/evgenygenov/miniforge3/envs/conformal/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import norm\n",
    "\n",
    "features = ['Month', 'Hour', 'hour_x', 'hour_y', 'month_x', 'month_y',\n",
    "'net_target-23', 'diffuse_solar_radiation+1', 'relative_humidity+1', 'drybulb_temp+1']\n",
    "target = 'net_target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data directory\n",
    "data_train = pd.read_csv('./data/extra_train.csv', index_col=0, parse_dates=['timestamp'])\n",
    "data_train.index = data_train.timestamp\n",
    "data_test = pd.read_csv('./data/extra_test.csv', index_col=0, parse_dates=['timestamp'])\n",
    "data_test.index = data_test.timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2021-10-13 14:00:00   2021-10-13 14:00:00\n",
       "2021-10-13 15:00:00   2021-10-13 15:00:00\n",
       "2021-10-13 16:00:00   2021-10-13 16:00:00\n",
       "2021-10-13 17:00:00   2021-10-13 17:00:00\n",
       "2021-10-13 18:00:00   2021-10-13 18:00:00\n",
       "                              ...        \n",
       "2022-07-30 19:00:00   2022-07-30 19:00:00\n",
       "2022-07-30 20:00:00   2022-07-30 20:00:00\n",
       "2022-07-30 21:00:00   2022-07-30 21:00:00\n",
       "2022-07-30 22:00:00   2022-07-30 22:00:00\n",
       "2022-07-30 23:00:00   2022-07-30 23:00:00\n",
       "Name: timestamp, Length: 6970, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['timestamp'][int((len(data_train) * 0.8)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgb(data, datat, features, target, seed=42):\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # set params for lgb point forecast regression\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "    }\n",
    "    # train test split the time series 80/20 \n",
    "    train = data.loc[data['timestamp'] < '2021-10-13 14:00:00']\n",
    "    valid = data.loc[data['timestamp'] >= '2021-10-13 14:00:00']\n",
    "    # train\n",
    "    x_train = train[features]\n",
    "    y_train = train[target]\n",
    "    x_valid = valid[features]\n",
    "    y_valid = valid[target]\n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid)\n",
    "    model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_valid], num_boost_round=1000, early_stopping_rounds=50, verbose_eval=100)\n",
    "    # predict\n",
    "    x_test = datat[features]\n",
    "    y_pred = model.predict(data[features], num_iteration=model.best_iteration)\n",
    "    y_pred_test = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "    # add an index to the predictions\n",
    "    y_pred = pd.DataFrame(y_pred, index=data.timestamp, columns=[target])\n",
    "    y_pred_test = pd.DataFrame(y_pred_test, index=datat.timestamp, columns=[target])\n",
    "    return y_pred, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 6968, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.398869\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's rmse: 0.0840273\tvalid_1's rmse: 0.101215\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_pred_test = run_lgb(data_train, data_test, features, target, seed=42)\n",
    "# add an hour column to the predictions\n",
    "y_pred['hour'] = y_pred.index.hour\n",
    "y_pred_test['hour'] = y_pred_test.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions to a point folder\n",
    "y_pred.to_csv('./data/point/train_fcst.csv')\n",
    "y_pred_test.to_csv('./data/point/test_fcst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('conformal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 | packaged by conda-forge | (default, May 11 2021, 06:27:18) \n[Clang 11.1.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0d3be591cc1f62bd6e576447eedd96beb36aab5b38925396e514c40c7291afb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
